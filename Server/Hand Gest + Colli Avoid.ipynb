{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "operational-blond",
   "metadata": {},
   "source": [
    "May need to run the whole code twice as for the first run, the JetBot will power off itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-geology",
   "metadata": {},
   "source": [
    "# Collision Avoidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "quarterly-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False) # A pre-trained 18 layer CNN network that can classify images into 1000 object categories\n",
    "model.fc = torch.nn.Linear(512, 4) # Change the last layer of the model, change second parameter according to how many labels there are"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-southeast",
   "metadata": {},
   "source": [
    "Load trained weights from pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "superb-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_resnet18_modified.pth')) # Change according to the path of the pre-trained model\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "model = model.eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-heritage",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "1. Convert from HWC layout to CHW layout\n",
    "2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "3. Transfer the data from CPU memory to GPU memory\n",
    "4. Add a batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "normalize = torchvision.transforms.Normalize(mean, std)\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-corrections",
   "metadata": {},
   "source": [
    "# Robot controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "young-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Forward\n",
    "# robot.forward(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Turn left\n",
    "# robot.set_motors(0.4,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-street",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Turn around\n",
    "# robot.right(0.5)\n",
    "# time.sleep(1)\n",
    "# robot.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop jetbot\n",
    "# robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-prediction",
   "metadata": {},
   "source": [
    "# Camera display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "solar-samba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\xâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)\n",
    "\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([image])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-accused",
   "metadata": {},
   "source": [
    "Make the JetBot move to prevent power draw issues later such as camera freeze\n",
    "\n",
    "Ensure camera is not frozen after running the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "great-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "robot.left(speed=0.3)\n",
    "time.sleep(0.5)\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-durham",
   "metadata": {},
   "source": [
    "1. Preprocess camera image\n",
    "2. Execute neural network\n",
    "3. Control what robot should do based on neural network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-murray",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "override = False\n",
    "stopthreads = False\n",
    "\n",
    "def update(change):\n",
    "    global robot, override\n",
    "    x = change['new'] # Camera input\n",
    "    x = preprocess(x)\n",
    "    y = model(x)\n",
    "    \n",
    "    # we apply the `softmax` function to normalize the output vector so it sums to 1 (which makes it a probability distribution)\n",
    "    y = F.softmax(y, dim=1)\n",
    "    \n",
    "    highestblock = torch.argmax(y).item() # Get label value with highest probability\n",
    "    \n",
    "    if highestblock == 0: # Front is blocked\n",
    "        override = True\n",
    "        print(\"Front blocked\")\n",
    "        robot.stop()\n",
    "    elif highestblock == 1: # Left is blocked\n",
    "        override = True\n",
    "        print(\"Left blocked\")\n",
    "        robot.right(0.5)\n",
    "        time.sleep(1.5)\n",
    "        robot.stop()\n",
    "    elif highestblock == 2: # Right is blocked\n",
    "        override = True\n",
    "        print(\"Right blocked\")\n",
    "        robot.left(0.5)\n",
    "        time.sleep(1.5)\n",
    "        robot.stop()\n",
    "    elif highestblock == 3: # Free\n",
    "        override = False\n",
    "    \n",
    "    time.sleep(0.001)\n",
    "\n",
    "def update_loop(): # Loop update function\n",
    "    print(\"Starting collision avoidance\")\n",
    "    global stopthreads\n",
    "    while True:\n",
    "        try: \n",
    "            update({'new': camera.value})\n",
    "        except:\n",
    "            print(\"Error occurred for collision avoidance\")\n",
    "            stopthreads = True\n",
    "            break\n",
    "        if stopthreads:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-terror",
   "metadata": {},
   "source": [
    "Call the function once to initialize and preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "update({'new': camera.value})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brutal-variety",
   "metadata": {},
   "source": [
    "# Socket Server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-collar",
   "metadata": {},
   "source": [
    "To allow the JetBot and the Hand Gesture Recognition application to communicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "exposed-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "def socket_server():\n",
    "    global stopthreads\n",
    "    s = socket.socket()\n",
    "\n",
    "    print(\"Socket successfully created\")\n",
    "\n",
    "    port = 12345\n",
    "\n",
    "    s.bind(('', port))\n",
    "\n",
    "    print(\"Socket binded to %s\" %(port))\n",
    "\n",
    "    s.listen(5)\n",
    "    print(\"Socket is listening\")\n",
    "    c, addr = s.accept()\n",
    "    print(f\"Connected to {addr}\")\n",
    "    \n",
    "    leftcount = 0\n",
    "    rightcount = 0\n",
    "\n",
    "    try:\n",
    "        with c:\n",
    "            while True:\n",
    "                input = c.recv(1024).decode()\n",
    "                if override == False:\n",
    "                    if input == \"Toggle Reverse\":\n",
    "                        robot.right(0.5)\n",
    "                        time.sleep(1)\n",
    "                        robot.stop()\n",
    "                    elif input == \"Left\":\n",
    "                        rightcount = 0\n",
    "                        rightmotor = 0.5 + (0.025 * leftcount)\n",
    "                        leftmotor = rightmotor / 2\n",
    "                        if leftmotor > 0.3:\n",
    "                            if rightmotor >= 0.85: \n",
    "                                robot.set_motors(0.3, 0.85)\n",
    "                            else:\n",
    "                                robot.set_motors(0.3, rightmotor)\n",
    "                        else: \n",
    "                            robot.set_motors(leftmotor, rightmotor)\n",
    "                        leftcount += 1\n",
    "                    elif input == \"Right\":\n",
    "                        leftcount = 0\n",
    "                        leftmotor = 0.5 + (0.025 * rightcount)\n",
    "                        rightmotor = leftmotor / 2\n",
    "                        if rightmotor > 0.3:\n",
    "                            if leftmotor >= 0.85:\n",
    "                                robot.set_motors(0.85, 0.3)\n",
    "                            else:\n",
    "                                robot.set_motors(leftmotor, 0.3)\n",
    "                        else:\n",
    "                            robot.set_motors(leftmotor, rightmotor)\n",
    "                        rightcount += 1\n",
    "                    elif input == \"Throttle\":\n",
    "                        rightcount = 0\n",
    "                        leftcount = 0\n",
    "                        robot.forward(0.5)\n",
    "                    elif input == \"Brake\" or \"Full Stop\":\n",
    "                        leftcount = 0\n",
    "                        rightcount = 0\n",
    "                        robot.stop()\n",
    "                    if not input:\n",
    "                        break\n",
    "                if stopthreads:\n",
    "                    s.close()\n",
    "                    break\n",
    "    except: \n",
    "        s.close()\n",
    "        print(\"Error occurred when communicating with client\")\n",
    "\n",
    "    print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-lesbian",
   "metadata": {},
   "source": [
    "# Threading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-tenant",
   "metadata": {},
   "source": [
    "To run both the while True loops (update_loop and socket_server) at once\n",
    "\n",
    "So that one loop does not have to end before running the other\n",
    "\n",
    "Needed as if both loops are implemented together, the program will be stuck at c, addr = s.accept() as it is waiting for a socket client to connect to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dependent-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = Thread(target = update_loop) # Collision avoidance\n",
    "t1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wrong-tolerance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socket successfully created\n",
      "Socket binded to 12345\n",
      "Socket is listening\n",
      "Connected to ('192.168.50.183', 50442)\n",
      "Error occurred when communicating with client\n",
      "Connection closed\n"
     ]
    }
   ],
   "source": [
    "t2 = Thread(target = socket_server) # Socket server\n",
    "t2.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-excellence",
   "metadata": {},
   "source": [
    "# Turn off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-going",
   "metadata": {},
   "source": [
    "Stop both the running functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopthreads = True\n",
    "t1.join()\n",
    "t2.join()\n",
    "print(\"Threads stoppped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-roberts",
   "metadata": {},
   "source": [
    "Stop camera input to prevent errors when re-running the notebook or when using other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-operator",
   "metadata": {},
   "source": [
    "Force close socket if there was a issue closing it earlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-spray",
   "metadata": {},
   "source": [
    "Stop the running functions individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-denver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
